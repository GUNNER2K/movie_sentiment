{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2cab4b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3232acde",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = pd.read_csv(r'C:\\Users\\satya\\Downloads\\sentiment-analysis-on-movie-reviews\\train.csv')\n",
    "movie_test = pd.read_csv(r'C:\\Users\\satya\\Downloads\\sentiment-analysis-on-movie-reviews\\test.csv')\n",
    "movie_sub = pd.read_csv(r'C:\\Users\\satya\\Downloads\\sentiment-analysis-on-movie-reviews\\sampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27ea3c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PhraseId  SentenceId  \\\n",
       "0               1           1   \n",
       "1               2           1   \n",
       "2               3           1   \n",
       "3               4           1   \n",
       "4               5           1   \n",
       "...           ...         ...   \n",
       "156055     156056        8544   \n",
       "156056     156057        8544   \n",
       "156057     156058        8544   \n",
       "156058     156059        8544   \n",
       "156059     156060        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \n",
       "0       A series of escapades demonstrating the adage ...          1  \n",
       "1       A series of escapades demonstrating the adage ...          2  \n",
       "2                                                A series          2  \n",
       "3                                                       A          2  \n",
       "4                                                  series          2  \n",
       "...                                                   ...        ...  \n",
       "156055                                          Hearst 's          2  \n",
       "156056                          forced avuncular chortles          1  \n",
       "156057                                 avuncular chortles          3  \n",
       "156058                                          avuncular          2  \n",
       "156059                                           chortles          2  \n",
       "\n",
       "[156060 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10fb4e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess2(phrase, new_col):\n",
    "    def remove_pattern(input_txt, pattern):\n",
    "        r = re.findall(pattern, input_txt)\n",
    "        for word in r:\n",
    "            input_txt = re.sub(word, \"\", input_txt)\n",
    "        return input_txt\n",
    "    movie_data[new_col] = np.vectorize(remove_pattern)(phrase, \"@[\\w]*\")\n",
    "    movie_data[new_col] = movie_data[new_col].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "    movie_data[new_col] = movie_data[new_col].apply(lambda x: \" \".join([w for w in x.split() if len(w)>3]))\n",
    "    tokenized_tweet = movie_data[new_col].apply(lambda x: x.split())\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    tokenized_tweet = tokenized_tweet.apply(lambda sentence: [stemmer.stem(word) for word in sentence])\n",
    "    for i in range(len(tokenized_tweet)):\n",
    "        tokenized_tweet[i] = \" \".join(tokenized_tweet[i])\n",
    "    \n",
    "    movie_data[new_col] = tokenized_tweet\n",
    "    return movie_data[new_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97b201cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\satya\\AppData\\Local\\Temp\\ipykernel_11040\\3865188208.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  movie_data[new_col] = movie_data[new_col].str.replace(\"[^a-zA-Z#]\", \" \")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>clean_phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>seri escapad demonstr adag that what good goos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "      <td>seri escapad demonstr adag that what good goos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "      <td>seri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "      <td>seri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "      <td>hearst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "      <td>forc avuncular chortl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "      <td>avuncular chortl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "      <td>avuncular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "      <td>chortl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PhraseId  SentenceId  \\\n",
       "0               1           1   \n",
       "1               2           1   \n",
       "2               3           1   \n",
       "3               4           1   \n",
       "4               5           1   \n",
       "...           ...         ...   \n",
       "156055     156056        8544   \n",
       "156056     156057        8544   \n",
       "156057     156058        8544   \n",
       "156058     156059        8544   \n",
       "156059     156060        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \\\n",
       "0       A series of escapades demonstrating the adage ...          1   \n",
       "1       A series of escapades demonstrating the adage ...          2   \n",
       "2                                                A series          2   \n",
       "3                                                       A          2   \n",
       "4                                                  series          2   \n",
       "...                                                   ...        ...   \n",
       "156055                                          Hearst 's          2   \n",
       "156056                          forced avuncular chortles          1   \n",
       "156057                                 avuncular chortles          3   \n",
       "156058                                          avuncular          2   \n",
       "156059                                           chortles          2   \n",
       "\n",
       "                                             clean_phrase  \n",
       "0       seri escapad demonstr adag that what good goos...  \n",
       "1          seri escapad demonstr adag that what good goos  \n",
       "2                                                    seri  \n",
       "3                                                          \n",
       "4                                                    seri  \n",
       "...                                                   ...  \n",
       "156055                                             hearst  \n",
       "156056                              forc avuncular chortl  \n",
       "156057                                   avuncular chortl  \n",
       "156058                                          avuncular  \n",
       "156059                                             chortl  \n",
       "\n",
       "[156060 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess2(movie_data['Phrase'],'clean_phrase')\n",
    "movie_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e660ff62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data['clean_phrase'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45dd8030",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size=100000\n",
    "onehot_repr1=[one_hot(phrase,voc_size)for phrase in movie_data['clean_phrase']] \n",
    "onehot_repr2=[one_hot(phrase,voc_size)for phrase in movie_data['Phrase']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "092b745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46161b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length=[]\n",
    "for x in movie_data['Phrase']:\n",
    "    length.append(len(x.split(' ')))\n",
    "max_length=max(length)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d63c764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0 ... 75358 96831 49969]\n",
      " [    0     0     0 ...  8794 23241 26199]\n",
      " [    0     0     0 ...     0     0  3954]\n",
      " ...\n",
      " [    0     0     0 ...     0 88574 20770]\n",
      " [    0     0     0 ...     0     0 88574]\n",
      " [    0     0     0 ...     0     0 20770]]\n"
     ]
    }
   ],
   "source": [
    "sent_length=max_length+10\n",
    "embedded_docs1=pad_sequences(onehot_repr1,padding='pre',maxlen=sent_length)\n",
    "embedded_docs2=pad_sequences(onehot_repr2,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "073efae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    79582\n",
       "3    32927\n",
       "1    27273\n",
       "4     9206\n",
       "0     7072\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d05b58d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_final1 = np.array(embedded_docs1)\n",
    "x_final2 = np.array(embedded_docs2)\n",
    "y_final = np.array(movie_data['Sentiment'])\n",
    "x_train1,x_test1,y_train1,y_test1 = train_test_split(x_final1,y_final,test_size=0.33, random_state=42)\n",
    "x_train2,x_test2,y_train2,y_test2 = train_test_split(x_final2,y_final,test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e51ca9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_length=max_length+10\n",
    "embedding_vector_features=10 ##features representation\n",
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(5,activation='softmax'))\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d7f3fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3268/3268 [==============================] - 283s 85ms/step - loss: 1.0215 - accuracy: 0.5894 - val_loss: 1.2117 - val_accuracy: 0.5331\n",
      "Epoch 2/10\n",
      "3268/3268 [==============================] - 160s 49ms/step - loss: 0.8713 - accuracy: 0.6454 - val_loss: 1.2641 - val_accuracy: 0.4778\n",
      "Epoch 3/10\n",
      "3268/3268 [==============================] - 158s 48ms/step - loss: 0.8273 - accuracy: 0.6611 - val_loss: 1.3589 - val_accuracy: 0.4616\n",
      "Epoch 4/10\n",
      "3268/3268 [==============================] - 157s 48ms/step - loss: 0.7976 - accuracy: 0.6721 - val_loss: 1.3249 - val_accuracy: 0.4633\n",
      "Epoch 5/10\n",
      "3268/3268 [==============================] - 162s 50ms/step - loss: 0.7735 - accuracy: 0.6808 - val_loss: 1.2835 - val_accuracy: 0.4600\n",
      "Epoch 6/10\n",
      "3268/3268 [==============================] - 164s 50ms/step - loss: 0.7521 - accuracy: 0.6883 - val_loss: 1.3154 - val_accuracy: 0.4477\n",
      "Epoch 7/10\n",
      "3268/3268 [==============================] - 163s 50ms/step - loss: 0.7291 - accuracy: 0.6977 - val_loss: 1.3568 - val_accuracy: 0.4348\n",
      "Epoch 8/10\n",
      "3268/3268 [==============================] - 160s 49ms/step - loss: 0.7097 - accuracy: 0.7052 - val_loss: 1.3574 - val_accuracy: 0.4482\n",
      "Epoch 9/10\n",
      "3268/3268 [==============================] - 159s 49ms/step - loss: 0.6911 - accuracy: 0.7125 - val_loss: 1.4070 - val_accuracy: 0.4279\n",
      "Epoch 10/10\n",
      "3268/3268 [==============================] - 159s 49ms/step - loss: 0.6745 - accuracy: 0.7195 - val_loss: 1.4824 - val_accuracy: 0.4118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x209c671ab20>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train1,y_train1,validation_data=(x_test1,y_test1),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "48ad3436",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_vector_features=10 ##features representation\n",
    "model2=Sequential()\n",
    "model2.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(Dense(128,activation='relu'))\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dense(64,activation='relu'))\n",
    "model2.add(Dropout(0.1))\n",
    "model2.add(LSTM(20))\n",
    "model2.add(Dense(5,activation='softmax'))\n",
    "model2.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6145141d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3268/3268 [==============================] - 193s 59ms/step - loss: 0.6581 - accuracy: 0.7255 - val_loss: 0.9365 - val_accuracy: 0.6457\n",
      "Epoch 2/10\n",
      "3268/3268 [==============================] - 194s 59ms/step - loss: 0.6408 - accuracy: 0.7321 - val_loss: 0.9490 - val_accuracy: 0.6453\n",
      "Epoch 3/10\n",
      "3268/3268 [==============================] - 190s 58ms/step - loss: 0.6258 - accuracy: 0.7380 - val_loss: 0.9554 - val_accuracy: 0.6433\n",
      "Epoch 4/10\n",
      "3268/3268 [==============================] - 185s 57ms/step - loss: 0.6103 - accuracy: 0.7438 - val_loss: 0.9784 - val_accuracy: 0.6384\n",
      "Epoch 5/10\n",
      "3268/3268 [==============================] - 187s 57ms/step - loss: 0.5966 - accuracy: 0.7484 - val_loss: 1.0086 - val_accuracy: 0.6426\n",
      "Epoch 6/10\n",
      "3268/3268 [==============================] - 196s 60ms/step - loss: 0.5834 - accuracy: 0.7548 - val_loss: 1.0064 - val_accuracy: 0.6431\n",
      "Epoch 7/10\n",
      "3268/3268 [==============================] - 194s 59ms/step - loss: 0.5704 - accuracy: 0.7589 - val_loss: 1.0359 - val_accuracy: 0.6413\n",
      "Epoch 8/10\n",
      "3268/3268 [==============================] - 194s 59ms/step - loss: 0.5578 - accuracy: 0.7638 - val_loss: 1.0512 - val_accuracy: 0.6411\n",
      "Epoch 9/10\n",
      "3268/3268 [==============================] - 196s 60ms/step - loss: 0.5455 - accuracy: 0.7687 - val_loss: 1.0681 - val_accuracy: 0.6363\n",
      "Epoch 10/10\n",
      "3268/3268 [==============================] - 196s 60ms/step - loss: 0.5346 - accuracy: 0.7733 - val_loss: 1.1078 - val_accuracy: 0.6362\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x209835c8eb0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train1,y_train1,validation_data=(x_test1,y_test1),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "62908818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1610/1610 [==============================] - 24s 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([8.2195284e-06, 1.1444017e-01, 8.8500178e-01, 5.4969615e-04,\n",
       "       1.4035220e-07], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=model.predict(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7db47f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 2, ..., 1, 1, 3], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "80cda962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66287</th>\n",
       "      <td>222348</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66288</th>\n",
       "      <td>222349</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66289</th>\n",
       "      <td>222350</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66290</th>\n",
       "      <td>222351</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66291</th>\n",
       "      <td>222352</td>\n",
       "      <td>11855</td>\n",
       "      <td>predictable scenario</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66292 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0         156061        8545   \n",
       "1         156062        8545   \n",
       "2         156063        8545   \n",
       "3         156064        8545   \n",
       "4         156065        8545   \n",
       "...          ...         ...   \n",
       "66287     222348       11855   \n",
       "66288     222349       11855   \n",
       "66289     222350       11855   \n",
       "66290     222351       11855   \n",
       "66291     222352       11855   \n",
       "\n",
       "                                                  Phrase  \n",
       "0      An intermittently pleasing but mostly routine ...  \n",
       "1      An intermittently pleasing but mostly routine ...  \n",
       "2                                                     An  \n",
       "3      intermittently pleasing but mostly routine effort  \n",
       "4             intermittently pleasing but mostly routine  \n",
       "...                                                  ...  \n",
       "66287             A long-winded , predictable scenario .  \n",
       "66288               A long-winded , predictable scenario  \n",
       "66289                                    A long-winded ,  \n",
       "66290                                      A long-winded  \n",
       "66291                               predictable scenario  \n",
       "\n",
       "[66292 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6b91a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(phrase, new_col):\n",
    "    def remove_pattern(input_txt, pattern):\n",
    "        r = re.findall(pattern, input_txt)\n",
    "        for word in r:\n",
    "            input_txt = re.sub(word, \"\", input_txt)\n",
    "        return input_txt\n",
    "    movie_test[new_col] = np.vectorize(remove_pattern)(phrase, \"@[\\w]*\")\n",
    "    movie_test[new_col] = movie_test[new_col].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "    movie_test[new_col] = movie_test[new_col].apply(lambda x: \" \".join([w for w in x.split() if len(w)>3]))\n",
    "    tokenized_tweet = movie_test[new_col].apply(lambda x: x.split())\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    tokenized_tweet = tokenized_tweet.apply(lambda sentence: [stemmer.stem(word) for word in sentence])\n",
    "    for i in range(len(tokenized_tweet)):\n",
    "        tokenized_tweet[i] = \" \".join(tokenized_tweet[i])\n",
    "    \n",
    "    movie_test[new_col] = tokenized_tweet\n",
    "    return movie_test[new_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "691785f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\satya\\AppData\\Local\\Temp\\ipykernel_11040\\1749866064.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  movie_test[new_col] = movie_test[new_col].str.replace(\"[^a-zA-Z#]\", \" \")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>clean_phrase_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>intermitt pleas mostli routin effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>intermitt pleas mostli routin effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>intermitt pleas mostli routin effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>intermitt pleas mostli routin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66287</th>\n",
       "      <td>222348</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario .</td>\n",
       "      <td>long wind predict scenario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66288</th>\n",
       "      <td>222349</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario</td>\n",
       "      <td>long wind predict scenario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66289</th>\n",
       "      <td>222350</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded ,</td>\n",
       "      <td>long wind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66290</th>\n",
       "      <td>222351</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded</td>\n",
       "      <td>long wind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66291</th>\n",
       "      <td>222352</td>\n",
       "      <td>11855</td>\n",
       "      <td>predictable scenario</td>\n",
       "      <td>predict scenario</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66292 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0         156061        8545   \n",
       "1         156062        8545   \n",
       "2         156063        8545   \n",
       "3         156064        8545   \n",
       "4         156065        8545   \n",
       "...          ...         ...   \n",
       "66287     222348       11855   \n",
       "66288     222349       11855   \n",
       "66289     222350       11855   \n",
       "66290     222351       11855   \n",
       "66291     222352       11855   \n",
       "\n",
       "                                                  Phrase  \\\n",
       "0      An intermittently pleasing but mostly routine ...   \n",
       "1      An intermittently pleasing but mostly routine ...   \n",
       "2                                                     An   \n",
       "3      intermittently pleasing but mostly routine effort   \n",
       "4             intermittently pleasing but mostly routine   \n",
       "...                                                  ...   \n",
       "66287             A long-winded , predictable scenario .   \n",
       "66288               A long-winded , predictable scenario   \n",
       "66289                                    A long-winded ,   \n",
       "66290                                      A long-winded   \n",
       "66291                               predictable scenario   \n",
       "\n",
       "                          clean_phrase_test  \n",
       "0      intermitt pleas mostli routin effort  \n",
       "1      intermitt pleas mostli routin effort  \n",
       "2                                            \n",
       "3      intermitt pleas mostli routin effort  \n",
       "4             intermitt pleas mostli routin  \n",
       "...                                     ...  \n",
       "66287            long wind predict scenario  \n",
       "66288            long wind predict scenario  \n",
       "66289                             long wind  \n",
       "66290                             long wind  \n",
       "66291                      predict scenario  \n",
       "\n",
       "[66292 rows x 4 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(movie_test['Phrase'],'clean_phrase_test')\n",
    "movie_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "81385a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size=100000\n",
    "onehot_repr1_test=[one_hot(phrase,voc_size)for phrase in movie_test['clean_phrase_test']] \n",
    "onehot_repr2_test=[one_hot(phrase,voc_size)for phrase in movie_test['Phrase']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "17b834ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0 ... 39489 57784 85493]\n",
      " [    0     0     0 ... 39489 57784 85493]\n",
      " [    0     0     0 ...     0     0     0]\n",
      " ...\n",
      " [    0     0     0 ...     0 34047 17286]\n",
      " [    0     0     0 ...     0 34047 17286]\n",
      " [    0     0     0 ...     0 11085 85339]]\n"
     ]
    }
   ],
   "source": [
    "sent_length=70\n",
    "embedded_docs1_test=pad_sequences(onehot_repr1_test,padding='pre',maxlen=sent_length)\n",
    "embedded_docs2_test2=pad_sequences(onehot_repr2_test,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8218bac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = np.array(embedded_docs1)\n",
    "test2 = np.array(embedded_docs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d3ce68da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66292"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "57c7ce51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2072/2072 [==============================] - 44s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "test_prediction1 = model.predict(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "177b88bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2072/2072 [==============================] - 43s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "test_prediction2 = model.predict(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5c3f2c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1=[]\n",
    "for x in test_prediction1:\n",
    "    label =np.argmax(x)\n",
    "    labels1.append(label)\n",
    "sentiments1=np.array(labels1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2dfc030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2=[]\n",
    "for x in test_prediction2:\n",
    "    label =np.argmax(x)\n",
    "    labels2.append(label)\n",
    "sentiments2=np.array(labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f11ac094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\satya'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7e8db163",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_sub['Sentiment']=sentiments1\n",
    "movie_sub.to_csv('sub1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6e67e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_sub['Sentiment']=sentiments2\n",
    "movie_sub.to_csv('sub2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ba459a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
